---
layout: post
title: "Neural Networks In Medicine : A Literature Review"
subtitle: "A literature review of several papers related to utilising neural networks in healthcare that I found interesting"
date: 2021-02-06 23:45:13 -0400
background: '/img/bg-post.jpg'
---
# Contents
##### 1. [Introduction](#Introduction)

##### 2. [Literature Review](#LiteratureReview)

##### 3. [Conclusion](#Conclusion)

##### 4. [References](#References)

<br></br>

## <a name="Introduction"></a>Introduction
One of the biggest advantages of Neural Networks over other machine learning algorithms is that feature extraction is part of the algorithmic process, in other algorithms, there needs to be a distinct selections of which features are important, whereas for neural networks, the weights assigned by the algorithm will eventually reflect which features were important for the output. They are also highly proficient at modelling non-linear complex relationships efficiently. Because of its generalization ability, Neural Networks are highly useful for unseen data as well once it has been properly trained. Due to all these factors, Neural Networks are used extensively in research involving forecasting, image recognition and more. In this literature review, the primary focus will be on Neural Networks use in the medical and healthcare field specifically.

## <a name="LiteratureReview"></a>Literature Review
This section presents the overviews of the research done by scholars and their contribution to the relevant field

**Lifeng He et.al (2010) [1]** presented a research study on the use of neural networks in medical image processing. Of the neural network types used, Hopfield neural networks (HNN) are the most commonly used for image preprocessing, due to its ability to reconstruct medical images as an optimization problem. For image segmentation, feed forward neural networks (FFNN) are most used due to the minimal amount of noise produced in the images and due to its low sensitivity based on selection of training sets. For object detection and recognition, back propagation neural networks are posed in most places. From the reviewed literature, it was found that neural networks produce a low amount of false negatives along with a high rate of overall identification. Regardless of the neural network used it was found that the time for applying a trained model was small, although, the amount of input data required for training was found to be a problem.

**Prashant Naresh et.al (2014) [2]** attempted to solve the problem of removing white Gaussian noise from CT scan images in the diagnosis process for lung cancer to aid in early detection, considering it’s a key challenge in diagnosis. Three classifiers are used, a support vector machine (SVM), an artificial neural network (ANN) and a k-neural network (k-NN) and are compared amongst each other. First, segmentation is done using Otsu’s threshold to remove whitespace and filter out the lung part of the scan, and then the preprocessed image is fed to a feature extraction phase where structural and textual features like area, equivalent diameter, energy and more are extracted and fed to the classifiers for training or testing. 111 and 73 images were taken for training and testing for stage 1 and stage 2 cancer respectively, out of which four-fifths were used for training and the rest for testing. The SVM model performed the best with a classification rate of 95.12% while the ANN and k-NN had a rate of 92.68% and 85.37% respectively.

**Dipali Joshi et.al (2010) [3]** developed a system using artificial neural networks to detect and classify brain lesions and tumors in MRI images. Histogram equalization was used to separate the tumor region from the rest of the image because tumors generally appear as very dark spots on the MRI image making it hard to segment using traditional methods. Image segmentation techniques were used to divide the image into discrete parts. Gray Level Co- occurrence Matrix (GLCM) features were used to differentiate between normal and abnormal brain tumors. Extracted features are added to a knowledge base for later comparison. Using the already available features and neuro fuzzy logic, the image is then classified into a grade of a tumor for Astrocytoma type of Brain Cancer. One reason that this system is novel is because not only can it detect the presence and location of the tumor, but also the type of tumor, which can usually be found out only by using an invasive biopsy. 

**Vairavan Srinivasan et.al (2007) [4]** proposes a neural network based Epilepsy detection system based on digitized electroencephalogram (EEG) signals. Traditionally these signals need to be analysed by an expert which are resource and time consuming. The paper uses two different neural networks,an Elman network (EN) and a probabilistic neural network (PNN). EN is used due to its ability to recognize temporal as well as spatial connections. A total of 100 EEG’s in two sets of data are used for normal and epileptic subjects signals. The system makes use of a recently formulated statistical parameter known as ApEn as a feature to classify as there is a sharp drop in this time domain feature during an epileptic seizure. There was high accuracy in the range of 99.35%-100% recorded for the EN model for detection. The EN performed better than the PNN. Compared to most neural networks this is comparatively less computationally intensive as it depends primarily on one feature, the ApEn which is also computationally non-intensive.

**Steven Walczak et.al (2005) [5]** designed a model using artificial neural networks to predict the transfusion costs of ER patients. This research differs from those before it in the same domain as it does so with minimal diagnostic information unlike in an information rich environment. Only variables that are present when the patient is brought to the hospital like age,sex and etiology of trauma are used to train the model to achieve this. This cuts down on time and cost greatly, which is a valuable commodity in these emergency situations. The dataset used was the transfusion records over a period of two years from 1996-1997 from an urban university hospital with 13 months for training and 11 months for testing. The back propagation ANN produced results on par or better than traditional computational methods, it was evaluated using its mean value error to determine how much it was over or under the ideal amount. This research also extends existing research by predicting transfusion needs for multiple transfusion products, rather than singular needs.

**Kuo-Sheng Cheng et.al (1996) [6]** attempted to solve a long standing problem of time and computationally intensive image segmentation by introducing a model known as a competitive Hopfield neural network (CHNN). A CHNN is a HNN with a winner takes all learning algorithm approach. Traditionally, image segmentation is done by keeping track of the spatial connectivity information of the images gray levels distribution. In this approach, the global distribution levels are recorded instead and a sense of spatial connectivity is kept by using the distance measurements from the center of the gray clusters.This also reduces the effort of computing all the weights for the variables during optimization. The energy function (termed the  Lyapunov energy function) of this model always converges during its iterations and makes the model flexible for a variety of different pattern recognition problems. The CHNN is especially useful for segmenting images with higher levels of noise compared to other methods.

**S. A. AlShehri et.al (2009) [7]** developed a feed-forward back-propagation neural network model to detect breast cancer by analysing electromagnetic waves which has not been done before in previous literature. The model was trained by using an artificial breast model and placing a tumor at different locations. The signals were used as input for the NN. This particular NN was used because it works well with limited datasets for training and testing. There were three separate sets of data using 1-D, 2-D and 3-D slices of the breast model along with waves of frequency ranging from 4-8 GHz. A limitation of this research is that the model used is a simple one, so ideally, more iterations with more complex models would verify the research better. The model has a 100% accuracy in detection of the presence of the model and a 94.4% accuracy in location detection in contrast to an approximate 70% detection rate using traditional methods. Another area where this research can advance is in its inability to distinguish between benign and malignant tumors.

**Mohammed Salah et.al (2018) [8]** developed a system to predict the rate of medical expenditure of people in a particular country using a back-propagation artificial neural network. The neural network used is a simple one with a linear sigmoid activation function. Factors like sex, age, education status and mroe were used as input variables with a training set of 5561 bills of expenditure for analysis. The purpose of the study was also to figure out which of these input factors had the most weight in determining the cost of someone's treatment. The most important factors were found to be whether they had previous or chronic ailments, their age, whether they had physical limitations and whether they had children. The neural network was able to accurately predict 88% of the test cases with average error 0.00023, showcasing its potential use. This research aso has potential in being used in predicting and showcasing the growth and progress of a country’s healthcare system.

An artificial neural network to diagnose Autism Spectrum Disorder (ASD), which is generally characterised by limited social skills and communication, was utilised by **Ibrahim M. Nasser et.al (2019) [9]**. This research is especially useful as the earlier someone is correctly diagnosed, the easier it is to help them. Traditionally, autism is diagnosed using the autism spectrum quotient which is  essentially a user taken test comprising 50 questions to analyse the participants cognitive strengths with relation to autism. A shortened form of this test known as the AQ-10-Adult test was used in this study which has 10 questions. A dataset consisting of previous testing results on an ASD screening app was used to train the ANN, along with metadata like age, gender, country of residence and so on. The model predicted with 100% accuracy with an average error rate of 0%. 

**Nesreen Samer El_Jerjawi et.al (2018) [10]** proposed a system to predict the onset of diabetes using an artificial neural network. The purpose of the study was also to find out the most important factors for diabetes prediction. A number of attributes such as Body Mass Index(BMI), number of pregnancies, Plasma Glucose level, age and more were used in this model as input with a single output variable denoting if healthy or diabetic. The system was implemented in a Just Neural Network (JNN) environment using a dataset of 1004 samples from the Association of diabetic’s city of Urmia, split into 767 samples for training and 237 for testing, over the course of 158,000 cycles for training. The accuracy obtained for diagnosing diabetes was found to be 87.3% with an average error of 0.010. Plasma Glucose level along with age and diastolic blood pressure were found to be the most important variables in the diagnosis.

**Zhi-Hua Zhou et.al (2002) [11]** used an artificial neural network ensemble to identify lung cancer cells. The proposed diagnosis procedure method was termed Neural-Ensemble based Detection (NED). Before computation, some minor preprocessing is done to smooth the image. It’s architecture consists of two levels. One where using a novel system called full voting, which essentially compiles the total output of the neural network ensemble by using the outputs of each individual constituent neural network if all of them present the same output, the cell is identified to be cancerous or normal. The second level then classifies the cell into one of five groups : adenocarcinoma, squamous carcinoma, small cell carcinoma, large cell carcinoma and normal based on another voting system which only accepts the top ranked prediction among all the predictions made by the constituent neural networks, this method is known as plurality voting. This system not only achieves a high prediction rate, but also a low false-negative rate, which is imperative in cancer diagnosis.

**Edward Choi et.al (2017) [12]** have developed a model to predict the onset of early heart failure using Recurrent Neural Networks (RNN). The raw data used is Electronic Health Records (EHR). This is done so because traditional methods ignore temporality, RNNs can be adapted to detect patterns among time-stamped events by using Gated Recurrent Units along with it as an extension framework. The raw data used is Electronic Health Records (EHR). The EHRs are represented as vectors by taking each of the N unique clinical events and representing them as N-dimensional vectors, which the GRU accepts as input. The dataset used was from Sutter Palo Alto Medical Foundation (SutterPAMF) across a period of over a decade. The data was divided into the ratios 5:1:1 for training, validation and testing respectively. Traditional logistic regression, an SVM, KNN and a multilayer perceptron (MLP) model were trained as well for evaluation and comparison purposes. The GRU model was found to have performed the best among the five models when it came to prediction time and error analysis.

**Pim Moeskops et.al (2017) [13]** have proposed a system to improve the segmentation of images of MRI scans of the brain using convolutional neural networks (CNN). CNN was particularly used due to its success in computer vision tasks. This research is particularly novel because unlike previous research it can be applied to images of developing neonates as well as young and old adults. The scale of the neural network is modified to a multiscale approach to allow the network to incorporate local details of the pixel clusters as well as their global spatial consistency. 57 total images were first used to tune the parameters over five different age groups. The segmentations were evaluated using a statistical measure known as the Dice coefficient and a mean surface distance between the automatic segmentation and a manually segmented image. The dice coefficients over all the datasets were found to be above 0.82 which signifies that the method produces accurate segmentation results compared to previous research and traditional methods.

A model to  classify heart rates using an artificial neural network was developed by U. **Rajendra Acharya et.al (2003) [14]**. The paper utilizes heart rate variability (HRV) to classify the heart rate to certain diseases. The heart rate electrocardiogram (ECG) is evaluated by studying the successive R-peaks of the waveform. Four parameters including average recorded heart rate and various energy levels are fed to the classifier. The heart rate can be classified into four categories : ischemic, complete heart block, sick sinus syndrome and normal. The neural network is made more efficient when used with a fuzzy equivalence relation, implemented using a fuzzy relation matrix. This essentially maps out a relation between each class of input with each classification group. The dataset used was a database of 342 patient samples, a training set of 276 and a testing set of 66, through 1000 iterations for computation. The accuracy obtained was recorded to b ein the ranges of 85-95% across the classification categories.

**E. Nasr-Esfahani et.al (2018) [15]** proposed a Convolutional Neural Network model (CNN) to classify and detect Melanoma, a type of skin cancer through clinical images. Research into automation of this task can be particularly impactful because of how difficult it can be to diagnose melanoma in early stages through traditional methods. First preprocessing is done on the clinical images to reduce noise  by using a gaussian filter and to remove the portions of healthy skin in the image as they are unnecessary for diagnosis. Automatic feature selection is used to ensure that deliberately defining features is not required and no unnecessary variables are used as features. A dataset of 170 images are used in a 8:2 ratio for training and training is done over 20,000 iterations. The final accuracy and other statistical measure was calculated by a mean  value through repeating the whole process 50 times to make it independent of the selected training set. An accuracy of 81% was achieved using the proposed model which is higher than that obtained using previous researched methods.

**U. Rajendra Acharya et.al (2018) [16]** have designed a model to automatically detect and diagnose seizures with a deep Convolutional Neural Network using EEG signals. When someone is experiencing a seizure, they have irregularities in their EEGs which can be hard to diagnose quickly before the seizure has lasting impact on the patient. The architecture of this particular CNN consists of three types of layers, namely the convolutional, the pooling and the fully connected layer each having different purposes like decreasing computational intensity and more. The dataset was obtained from Bonn University, Germany. 30% of the dataset was used to test the model after 150 iterations were run. A 10-fold cross validation method was used for validation, repeating the whole process another 10 times to ensure there was no bias due to selection of training and testing set. An accuracy of 90% was achieved with 1% false negatives and 9% false positives.

A system to detect coronary artery disease using a hybrid model neural network was proposed by **Zeinab Arabasadi et.al (2017) [17]**. The dataset used was information from 303 patients with 54 features each. Among these 54 features, four different ranking methods were used for feature selection. The reason this is considered a hybrid model is because the initial weights of the selected features were determined using a genetic algorithm, an algorithm which takes inspiration from biological concepts of selection based on a fitness function, mutation and more. The most weighted features were found to be presence of typical chest pain, atypical chest pain and age. The model was found to perform better than not only traditional methods, but other traditional neural network models. The accuracy, sensitivity and specificity were found to be 93.85%, 97% and 92% respectively.  To move forward with this research, the hybrid approach needs to be done with more types of neural networks.

**Wenqing Sun et.al (2017) [18]** have designed a system to diagnose breast cancer with unlabeled data using a deep Convolutional Neural Network (CNN) with a semi-supervised learning (SSL) scheme. This scheme is used to combat the difficulty in acquiring a large dataset of labeled images, SSL uses a small dataset of labeled images and a large dataset of unlabeled ones. There were 21 total computational features used for the model including entropy, density and more. A weighted graph was used to compare the labeled data and unlabeled data. From the total 3158 regions of interest used as data, 2400 were used for training and 758 were used for testing with 100 iterations.minor preprocessing was done for  few images if they were not of adequate size. There was an accuracy of 82.43% obtained for labelling the data. This research in particular helps address the problem of large datasets being required to efficiently train neural networks.

A system to diagnose gastric cancer using endoscopic images through use of a Convolutional Neural Network (CNN) was proposed by **Toshiaki Hirasawa et.al (2018) [19]**. The dataset of 13,584 endoscopic images were obtained from two hospitals and two clinics in Japan over the course of twelve years. The neural network was constructed on the Single Shot MultiBox Detector (SSD), developed at the Berkeley Vision and Learning Center, a 16 layer CNN architecture. Each image was preprocessed by a resize to a 300*300 pixel size and a global learning rate of 0.0001 was chosen. Each image contained at least one gastric lesion and multiple images were used for one lesion to include possible differences in lighting and perspective that the model might encounter. In the study, the model identified 92.2% of the lesions, the few missed were those that are hard to be identified by even expert endoscopists. There are a few limitations on this research, being that all the images were high quality and from one type of image, and that the images used needed to be double checked, which can be time consuming.

A system to analyse and classify heart diseases using Artificial Neural Networks (ANN) was proposed by **K.Usha Rani (2011) [20]**. For the data for training and testing, the dataset was obtained from the Cleaveland dataset which is freely and readily available on the internet. 414 instances were taken and 13 attributes were used including age, sex, cholestorol and more. A linear scaling formula was used to convert the inputs to an output ranging from 0 to 1. These inputs were classified into four classes, class 0 for a normal heart, class 1 for the first stroke, class 2 for the second stroke, and class 3 to signify the end of life. The sum of squares formula was used as the error function to evaluate when to stop training the model. Various iterations were done with different ratios of training to testing data, ranging from 1:3 to 3.5:1. With increase of the training data taken, the accuracy observed increased as well, with the highest accuracy observed being 94% efficient.

**Sanjay Bhatikar et.al (2001) [21]** have developed an Artificial Neural Network based model to screen between pathological and innocent heart murmurs in children. Digital recordings of the heart beats of 69 children, specifically from the left midsternal border in the supine position, from a cardiology clinic were used as the dataset. All of these cases were examined by pediatricians through echocardiographic confirmation to label the cases correctly before training. Optimal recordings with minimal background noise were chosen and processed using digital signal analysis first. The primary parameter for the network was the input frequency, and the spectral resolution. Sensitivities and specificities above 90% on average were observed, there was a noticeable drop off with decrease in spectral resolution from 1 to 3 Hz. This research is especially useful as human ears physically cannot catch some of the intricacies of these. The research can be furthered by acquiring more data for training and by increasing the spectral and frequency range, although this might increase computational load as well.

## <a name="Conclusion"></a>Conclusion
Most of the research was geared towards image recognition. This is probably due to the fact that Neural Networks are best when working with unstructured data. Its use in areas like general healthcare and decision making appear limited. 

A consistent problem with most of the research reviewed seems to be the amount of preprocessing required due to the format of these medical images, technical abnormalities between images as well can throw off these models. The amount of data required is an unsolved problem in this field. When training a Neural Network, a large amount of data is typically required. For medical images, acquiring this data is not only difficult in terms of volume but also the sheer variety of cases and scenarios that need to be covered for diagnosis type problems. If not properly trained, a lot of edge cases will potentially not be caught. In the medical field, a wrong decision is a lot more costlier than in other fields which is easy to forget when one looks at the above 90% accuracies for most of these models. 

All of the research is clearly defined and justifies its uses. The research is primarily theoretical, most being designed and tested as models rather than used in real life situations. Neural Networks are particularly useful in this field because they are better at modelling higher dimensional non- linear relations, this is evident in pattern recognition problems that are hard for humans to grasp. 

Considering the computing potential, as well as the difficulty in establishing a sense of accountability if something goes wrong, for the future of the use of Neural Network in the medical field, using these systems in tandem with doctors manual practice seems more viable presently rather than full automation.This would enable current practitioners to utilise the superior pattern recognition and computation of Neural Networks while also still giving responsibility to them to help out with exceptions that need an experts judgement as well as take accountability for the mistakes made in those cases. In the future, when image segmentation and preprocessing techniques are improved, and perhaps when larger, more exhaustive datasets are readily available, will Neural Networks be ready for unadulterated use.

## <a name="References"></a>References
**[1]Shi, Zhenghao, and Lifeng He. "Application of neural networks in medical image processing." In Proceedings of the second international symposium on networking and network security, pp. 2-4. 2010.**

**[2]Naresh, Prashant, and Dr Rajashree Shettar. "Early detection of lung cancer using neural network techniques." Prashant Naresh Int. Journal of Engineering Researchand Applications 4, no. 8 (2014): 78-83.**

**[3]Joshi, Dipali M., N. K. Rana, and VMi Misra. "Classification of brain cancer using artificial neural network." In 2010 2nd International Conference on Electronic Computer Technology, pp. 112-116. IEEE, 2010.**

**[4]Srinivasan, Vairavan, Chikkannan Eswaran, and Natarajan Sriraam. "Approximate entropy-based epileptic EEG detection using artificial neural networks." IEEE Transactions on information Technology in Biomedicine 11, no. 3 (2007): 288-295.**

**[5]Walczak, Steven. "Artificial neural network medical decision support tool: predicting transfusion requirements of ER patients." IEEE Transactions on Information Technology in Biomedicine 9, no. 3 (2005): 468-474.**

**[6]Cheng, Kuo-Sheng, Jzau-Sheng Lin, and Chi-Wu Mao. "The application of competitive Hopfield neural network to medical image segmentation." IEEE transactions on medical imaging 15, no. 4 (1996): 560-567.**

**[7]AlShehri, Saleh Ali, and Sabira Khatun. "UWB imaging for breastr cancer detection using neural network." Progress In Electromagnetics Research 7 (2009): 79-93.**

**[8]Salah, Mohammed, Khaled Altalla, Ahmed Salah, and Samy S. Abu-Naser. "Predicting Medical Expenses Using Artificial Neural Network." International Journal of Engineering and Information Systems (IJEAIS) 2, no. 20 (2018): 11-17.**

**[9]Nasser, Ibrahim M., Mohammed Al-Shawwa, and Samy S. Abu-Naser. "Artificial Neural Network for Diagnose Autism Spectrum Disorder." (2019).**

**[10]El_Jerjawi, Nesreen Samer, and Samy S. Abu-Naser. "Diabetes prediction using artificial neural network." (2018).**

**[11]Zhou, Zhi-Hua, Yuan Jiang, Yu-Bin Yang, and Shi-Fu Chen. "Lung cancer cell identification based on artificial neural network ensembles." Artificial Intelligence in Medicine 24, no. 1 (2002): 25-36.**

**[12]Choi, Edward, Andy Schuetz, Walter F. Stewart, and Jimeng Sun. "Using recurrent neural network models for early detection of heart failure onset." Journal of the American Medical Informatics Association 24, no. 2 (2017): 361-370.**

**[13]Moeskops, Pim, Max A. Viergever, Adriënne M. Mendrik, Linda S. De Vries, Manon JNL Benders, and Ivana Išgum. "Automatic segmentation of MR brain images with a convolutional neural network." IEEE transactions on medical imaging 35, no. 5 (2016): 1252-1261.**

**[14]Acharya, U. Rajendra, P. Subbanna Bhat, S. Sitharama Iyengar, Ashok Rao, and Sumeet Dua. "Classification of heart rate data using artificial neural network and fuzzy equivalence relation." Pattern recognition 36, no. 1 (2003): 61-68.**

**[15]Nasr-Esfahani, Ebrahim, Shadrokh Samavi, Nader Karimi, S. Mohamad R. Soroushmehr, Mohammad H. Jafari, Kevin Ward, and Kayvan Najarian. "Melanoma detection by analysis of clinical images using convolutional neural network." In 2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 1373-1376. IEEE, 2016.**

**[16]Acharya, U. Rajendra, Shu Lih Oh, Yuki Hagiwara, Jen Hong Tan, and Hojjat Adeli. "Deep convolutional neural network for the automated detection and diagnosis of seizure using EEG signals." Computers in biology and medicine 100 (2018): 270-278.**

**[17]Arabasadi, Zeinab, Roohallah Alizadehsani, Mohamad Roshanzamir, Hossein Moosaei, and Ali Asghar Yarifard. "Computer aided decision making for heart disease detection using hybrid neural network-Genetic algorithm." Computer methods and programs in biomedicine 141 (2017): 19-26.**

**[18]Sun, Wenqing, Tzu-Liang Bill Tseng, Jianying Zhang, and Wei Qian. "Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data." Computerized Medical Imaging and Graphics 57 (2017): 4-9.**

**[19]Hirasawa, Toshiaki, Kazuharu Aoyama, Tetsuya Tanimoto, Soichiro Ishihara, Satoki Shichijo, Tsuyoshi Ozawa, Tatsuya Ohnishi et al. "Application of artificial intelligence using a convolutional neural network for detecting gastric cancer in endoscopic images." Gastric Cancer 21, no. 4 (2018): 653-660.**

**[20]Rani, K. Usha. "Analysis of heart diseases dataset using neural network approach." arXiv preprint arXiv:1110.2626 (2011).**

**[21]DeGroff, Curt G., Sanjay Bhatikar, Jean Hertzberg, Robin Shandas, Lilliam Valdes-Cruz, and Roop L. Mahajan. "Artificial neural network–based method of screening heart murmurs in children." Circulation 103, no. 22 (2001): 2711-2716.**
